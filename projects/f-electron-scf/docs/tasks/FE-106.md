# FE-106: DFT+U PW GPU/DCU 加速适配

## Objective

确保 PW DFT+U 在 GPU/DCU 上正确运行。适配 GPU kernel、device memory 操作。

## Reference Code

### Source Code (zdy-tmp 参考实现)

**`/root/abacus-zdy-tmp/source/source_pw/module_pwdft/kernels/cuda/onsite_op.cu`** (~217 lines)
- DFT+U GPU kernel: `__global__ void onsite_op()` — 将 V_U 矩阵应用到 becp
  - 输入: `vu` (V_U 势), `becp` (投影系数), `orb_l_iat`, `ip_iat`, `ip_m`, `vu_begin_iat`
  - 输出: `ps` (V_U|β⟩ 的系数)
  - Block 并行: 投影子 (ip), Thread 并行: 能带 (ib)
- DeltaSpin GPU kernel: `__global__ void onsite_op()` — 将 λ 系数应用到 becp
  - 输入: `lambda_coeff`, `becp`
  - 输出: `ps`

### Target Code (develop 分支)

**`/root/abacus-develop/source/source_pw/module_pwdft/kernels/onsite_op.h`** (62 lines)
- `hamilt::onsite_ps_op<FPTYPE, Device>` — 模板结构体，CPU/GPU 特化
- 两个 `operator()` 重载: DeltaSpin 版本 (lambda_coeff) 和 DFT+U 版本 (vu)

**`/root/abacus-develop/source/source_pw/module_pwdft/kernels/onsite_op.cpp`** (86 lines)
- CPU 实现

**`/root/abacus-develop/source/source_pw/module_pwdft/kernels/cuda/onsite_op.cu`** (134 lines)
- CUDA 实现 — 需对比 zdy-tmp 版本，确认是否缺少 DFT+U 相关 kernel

**`/root/abacus-develop/source/source_pw/module_pwdft/kernels/rocm/onsite_op.hip.cu`** (134 lines)
- ROCm/DCU 实现 — 需与 CUDA 版本同步

**`/root/abacus-develop/source/source_pw/module_pwdft/onsite_proj_tools.cpp`** (1020 lines)
- `cal_becp()`, `cal_force_dftu()`, `cal_stress_dftu()` — 需确保 GPU 路径正确
- device memory 分配/释放使用 `resmem_complex_op()` / `delmem_complex_op()`

### Prior Art

**`/root/abacus-develop/source/source_pw/module_pwdft/kernels/cuda/`** — 其他 GPU kernel 的实现模式
- `THREADS_PER_BLOCK = 256`
- Block-level 并行 + Thread-level 并行
- 模板特化 `base_device::DEVICE_GPU`

## Implementation Guide

### Architecture Decisions

- GPU kernel 通过模板特化 `onsite_ps_op<FPTYPE, base_device::DEVICE_GPU>` 实现
- CPU 和 GPU 共享相同的上层调用接口（`Onsite_Proj_tools` 模板类）
- device memory 操作通过 `base_device` 命名空间的 op 结构体抽象

### zdy-tmp vs develop GPU kernel 差异

| 特性 | zdy-tmp (217 lines) | develop (134 lines) | 需要做的 |
|------|---------------------|---------------------|----------|
| DeltaSpin kernel | ✓ | ✓ | 验证一致 |
| DFT+U kernel | ✓ | ✓ | 验证一致 |
| nspin=1/2 支持 | ✓ | 可能缺失 | 需检查 npol 处理 |
| ctx 参数 | 需要 | 不需要 | API 差异，需适配 |

### Critical Implementation Details

- **Device memory**: `eff_pot_pw` 数组需要在 GPU 上分配并从 CPU 拷贝
- **becp 在 GPU 上**: `cal_becp()` 的 GEMM 调用使用 cuBLAS，becp 结果留在 GPU
- **force/stress GPU 路径**: `cal_force_dftu()` 和 `cal_stress_dftu()` 中的 GEMM 也需要 GPU 路径
- **同步点**: 力和应力的最终归约需要 device→host 拷贝
- **ROCm 兼容**: `.hip.cu` 文件需与 `.cu` 文件保持同步

## TDD Test Plan

### Tests to Write FIRST

```cpp
#ifdef __CUDA
TEST_F(DftuGpuTest, GpuCpuConsistency) {
    // GPU 和 CPU 结果应完全一致
    auto locale_cpu = run_cal_occ_pw<base_device::DEVICE_CPU>(psi, wg, cell);
    auto locale_gpu = run_cal_occ_pw<base_device::DEVICE_GPU>(psi, wg, cell);
    for (int i = 0; i < locale_size; i++)
        EXPECT_NEAR(std::abs(locale_cpu[i] - locale_gpu[i]), 0.0, 1e-10);
}

TEST_F(DftuGpuTest, ForceGpuCpuConsistency) {
    auto force_cpu = run_force<base_device::DEVICE_CPU>();
    auto force_gpu = run_force<base_device::DEVICE_GPU>();
    for (int i = 0; i < 3*nat; i++)
        EXPECT_NEAR(force_cpu[i], force_gpu[i], 1e-10);
}
#endif
```

## Acceptance Criteria

- [ ] CUDA 编译通过
- [ ] GPU 结果与 CPU 一致（locale, energy, force, stress 误差 < 1e-10）
- [ ] ROCm/DCU 编译通过并结果一致
