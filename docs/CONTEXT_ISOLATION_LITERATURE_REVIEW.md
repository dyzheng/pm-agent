# ä¸Šä¸‹æ–‡éš”ç¦»çš„æ–‡çŒ®è°ƒç ”ç³»ç»Ÿ

## é—®é¢˜å®šä¹‰

### ä¸ºä»€ä¹ˆéœ€è¦æ–‡çŒ®è°ƒç ”ï¼Ÿ

è¯„ä¼°ç§‘ç ”ä»»åŠ¡çš„**å…ˆè¿›æ€§**éœ€è¦å¯¹æ¯”**é¢†åŸŸæœ€æ–°è¿›å±•**ï¼š
- âŒ ä»…å‡­å…³é”®è¯æ— æ³•åˆ¤æ–­æ˜¯å¦ä¸ºå‰æ²¿é—®é¢˜
- âŒ å¯èƒ½é”™è¿‡æ›´å…ˆè¿›çš„æ›¿ä»£æ–¹æ³•
- âŒ æ— æ³•ç»™å‡ºåŸºäº SOTA çš„æ”¹è¿›å»ºè®®
- âœ… éœ€è¦æŸ¥é˜… 2024-2026 å¹´çš„æœ€æ–°æ–‡çŒ®

### ä¸Šä¸‹æ–‡çˆ†ç‚¸é£é™©

**é—®é¢˜è§„æ¨¡ä¼°ç®—ï¼š**
```
æ–‡çŒ®è°ƒç ”çš„ä¸Šä¸‹æ–‡æ¶ˆè€—ï¼š
- 42 ä¸ªä»»åŠ¡ Ã— 5 ç¯‡è®ºæ–‡ Ã— 1000 tokens/æ‘˜è¦ = 210k tokens
- åŠ ä¸Šåˆ†æè®¨è®ºï¼š~300k tokens
- å½“å‰ä¼šè¯å‰©ä½™ï¼š~110k tokens

ç»“è®ºï¼šâŒ æ— æ³•åœ¨ä¸»ä¼šè¯ä¸­å®Œæˆ
```

**å…·ä½“åœºæ™¯ï¼š**
```
ç”¨æˆ·è¯·æ±‚ï¼šè¯„ä¼° FE-205 (çº¦æŸDFT) çš„å…ˆè¿›æ€§

ä¼ ç»Ÿæ–¹å¼ (ä¼šå¯¼è‡´ä¸Šä¸‹æ–‡çˆ†ç‚¸):
1. WebSearch "constrained DFT f-electron 2024"
   â†’ è¿”å› 10 ç¯‡è®ºæ–‡é“¾æ¥ (~2k tokens)
2. WebFetch æ¯ç¯‡è®ºæ–‡æ‘˜è¦
   â†’ 10 Ã— 1k = 10k tokens
3. åˆ†æå’Œå¯¹æ¯”
   â†’ 5k tokens è®¨è®º
4. é‡å¤ 42 ä¸ªä»»åŠ¡
   â†’ æ€»è®¡ ~650k tokens âŒ çˆ†ç‚¸

ä¸Šä¸‹æ–‡éš”ç¦»æ–¹å¼:
1. å¯åŠ¨ç‹¬ç«‹ Agent
   â†’ åœ¨æ–°ä¼šè¯ä¸­å®Œæˆæ­¥éª¤ 1-3
   â†’ è¿”å›ç²¾ç‚¼çš„ 1 é¡µæ‘˜è¦ (~500 tokens)
2. ä¸»ä¼šè¯åªè¯»å–æ‘˜è¦
   â†’ 42 Ã— 500 = 21k tokens âœ… å¯æ§
```

---

## è§£å†³æ–¹æ¡ˆæ¶æ„

### æ ¸å¿ƒæ€æƒ³ï¼šåˆ†å±‚å¤„ç† + ä¸Šä¸‹æ–‡éš”ç¦»

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 1: Main Session (pm-agent)                    â”‚
â”‚ - å¿«é€Ÿä»»åŠ¡è¯„å®¡ (å…³é”®è¯å¯å‘å¼)                        â”‚
â”‚ - è¯†åˆ«é«˜ä¼˜å…ˆçº§ä»»åŠ¡                                   â”‚
â”‚ - åªä¿ç•™ç²¾ç‚¼ç»“æœ (<5k tokens/ä»»åŠ¡)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚ å¯åŠ¨ N ä¸ªç‹¬ç«‹ Agent (N â‰¤ 10)
               â”‚ æ¯ä¸ª Agent åœ¨éš”ç¦»çš„ä¸Šä¸‹æ–‡ä¸­å·¥ä½œ
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 2: Literature Review Agents (isolated)        â”‚
â”‚ - Agent 1: FE-205 çº¦æŸDFTæ–‡çŒ®è°ƒç ”                   â”‚
â”‚ - Agent 2: FE-200 Kerkeré¢„å¤„ç†æ–‡çŒ®è°ƒç ”             â”‚
â”‚ - Agent 3: FE-D-C2 GNNå æ®çŸ©é˜µæ–‡çŒ®è°ƒç ”             â”‚
â”‚ ...                                                  â”‚
â”‚                                                      â”‚
â”‚ æ¯ä¸ª Agent ç‹¬ç«‹æ‰§è¡Œ:                                â”‚
â”‚   1. WebSearch æŸ¥æ‰¾æœ€æ–°è®ºæ–‡ (2024-2026)            â”‚
â”‚   2. WebFetch è¯»å– 3-5 ç¯‡å…³é”®è®ºæ–‡æ‘˜è¦              â”‚
â”‚   3. åˆ†æ: å…ˆè¿›æ€§å¯¹æ¯”ã€Gap è¯†åˆ«                     â”‚
â”‚   4. ç”Ÿæˆç²¾ç‚¼æ‘˜è¦ (<500 tokens)                     â”‚
â”‚   5. ä¿å­˜åˆ°æ–‡ä»¶                                     â”‚
â”‚                                                      â”‚
â”‚ ä¸Šä¸‹æ–‡æ¶ˆè€—: æ¯ä¸ª Agent ~50k tokens                  â”‚
â”‚ ä½†å½¼æ­¤éš”ç¦»ï¼Œä¸ä¼šç´¯ç§¯                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚ è¿”å›æ–‡ä»¶è·¯å¾„: literature/{task_id}.json
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 1: Main Session                               â”‚
â”‚ - Read ç²¾ç‚¼ç»“æœæ–‡ä»¶ (~500 tokens/ä»»åŠ¡)              â”‚
â”‚ - æ•´åˆåˆ°ä¼˜åŒ–æ–¹æ¡ˆ                                     â”‚
â”‚ - ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š                                       â”‚
â”‚                                                      â”‚
â”‚ æ€»ä¸Šä¸‹æ–‡æ¶ˆè€—: 10 Ã— 500 = 5k tokens âœ…               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å…³é”®è®¾è®¡

#### 1. ç»“æ„åŒ–çš„ç²¾ç‚¼è¾“å‡º

**Literature Review Agent çš„è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼é™åˆ¶ï¼‰ï¼š**
```json
{
  "task_id": "FE-205",
  "query_terms": ["constrained DFT", "f-electron", "occupation control"],

  // æ¯ä¸ªå­—æ®µæœ€å¤š 2 å¥è¯
  "recent_advances": "æœ€æ–°è¿›å±• (2024-2026) ...",
  "state_of_art": "å½“å‰æœ€ä½³æ–¹æ³• ...",
  "gaps_identified": "æœªè§£å†³çš„é—®é¢˜ ...",

  "novelty_level": "frontier|advanced|incremental|routine",
  "novelty_justification": "åˆ¤æ–­ä¾æ® ...",

  // 2-5 æ¡å»ºè®®
  "improvement_suggestions": [
    "å…·ä½“æ”¹è¿›å»ºè®® 1",
    "å…·ä½“æ”¹è¿›å»ºè®® 2"
  ],

  // 1-3 ä¸ªæ›¿ä»£æ–¹æ³•
  "alternative_approaches": [
    "æ›¿ä»£æ–¹æ³• 1 (from Paper X, 2024)",
    "æ›¿ä»£æ–¹æ³• 2 (from Paper Y, 2025)"
  ],

  // ä»…æ ‡é¢˜ï¼Œä¸å«æ‘˜è¦
  "key_papers": [
    "Paper title 1 (2024, Journal)",
    "Paper title 2 (2025, Journal)"
  ]
}
```

**å­—ç¬¦é™åˆ¶ï¼š**
- æ¯ä¸ªæ–‡æœ¬å­—æ®µï¼šæœ€å¤š 2 å¥è¯
- æ€»å“åº”ï¼š<2000 å­—ç¬¦
- âŒ ç¦æ­¢è¿”å›å®Œæ•´è®ºæ–‡æ‘˜è¦
- âœ… åªè¿”å›å¯æ‰§è¡Œçš„æ´å¯Ÿ

#### 2. æ‰¹é‡å¤„ç†ç­–ç•¥

```python
# åªä¸ºé«˜ä¼˜å…ˆçº§ä»»åŠ¡è¿è¡Œæ–‡çŒ®è°ƒç ”
high_priority_tasks = [
    task for task in tasks
    if task.priority_score >= 80.0
][:10]  # æœ€å¤š 10 ä¸ª

# å¹¶è¡Œå¯åŠ¨ Agent (å¦‚æœæ”¯æŒ)
results = parallel_literature_review(high_priority_tasks)
```

**ä¼˜å…ˆçº§è¿‡æ»¤ï¼š**
- ä¼˜å…ˆçº§ â‰¥ 80 åˆ†çš„ä»»åŠ¡
- é™åˆ¶æœ€å¤š 10 ä¸ªä»»åŠ¡
- æ€»ä¸Šä¸‹æ–‡ï¼š10 Ã— 500 = 5k tokens

#### 3. ç¼“å­˜æœºåˆ¶

```python
# ç»“æœç¼“å­˜åœ¨æ–‡ä»¶ä¸­
literature/
â”œâ”€â”€ FE-205_literature.json
â”œâ”€â”€ FE-200_literature.json
â”œâ”€â”€ FE-D-C2_literature.json
â””â”€â”€ summary.json

# åç»­è¯„å®¡ç›´æ¥è¯»å–ï¼Œä¸éœ€è¦é‡æ–°è°ƒç ”
if cache_file.exists():
    result = load_from_cache(cache_file)
else:
    result = run_agent_literature_review(task)
    save_to_cache(result, cache_file)
```

---

## å®ç°é˜¶æ®µ

### Phase 1: Placeholder æ¨¡å¼ âœ… å·²å®ç°

**å½“å‰çŠ¶æ€ï¼š**
- âœ… æ¡†æ¶æ­å»ºå®Œæˆ
- âœ… ç»“æ„åŒ–è¾“å‡ºæ ¼å¼å®šä¹‰
- âœ… åŸºäºå…³é”®è¯çš„å¯å‘å¼è¯„ä¼°ï¼ˆplaceholderï¼‰
- âœ… æ–‡ä»¶ç¼“å­˜æœºåˆ¶
- âœ… æ‰¹é‡å¤„ç†é€»è¾‘

**è¿è¡Œç¤ºä¾‹ï¼š**
```bash
# è¿è¡Œå¢å¼ºç‰ˆè¯„å®¡ (placeholder æ¨¡å¼)
python tools/enhanced_review.py --max-lit-tasks 5

# è¾“å‡º:
# Phase 1: å¿«é€Ÿä»»åŠ¡è¯„å®¡
# Phase 2: æ–‡çŒ®è°ƒç ” (placeholder)
# Phase 3: ç”Ÿæˆå¢å¼ºå»ºè®®
```

**ç”Ÿæˆæ–‡ä»¶ï¼š**
```
projects/f-electron-scf/
â”œâ”€â”€ research/
â”‚   â””â”€â”€ literature/
â”‚       â”œâ”€â”€ FE-205_literature.json  â† ç²¾ç‚¼çš„æ–‡çŒ®æ‘˜è¦
â”‚       â”œâ”€â”€ FE-200_literature.json
â”‚       â””â”€â”€ summary.json
â”œâ”€â”€ research_review_enhanced.md     â† å¢å¼ºç‰ˆæŠ¥å‘Š
â””â”€â”€ research_review_enhanced.json
```

**Placeholder çš„å±€é™æ€§ï¼š**
- âŒ æ²¡æœ‰å®é™…æŸ¥è¯¢æœ€æ–°æ–‡çŒ®
- âŒ åŸºäºå…³é”®è¯å¯å‘å¼ï¼Œå¯èƒ½ä¸å‡†ç¡®
- âœ… ä½†è¯æ˜äº†æ¶æ„å¯è¡Œæ€§
- âœ… ä¸Šä¸‹æ–‡æ§åˆ¶åœ¨ 5k tokens å†…

### Phase 2: Agent-based æ–‡çŒ®è°ƒç ” ğŸš§ å¾…å®ç°

**å‡çº§æ–¹æ¡ˆï¼š**

#### Step 1: é›†æˆ Task tool

```python
# åœ¨ literature_review.py ä¸­
def run_literature_review_for_task(task, state, output_dir, *, use_agent=True):
    if not use_agent:
        return _placeholder_literature_review(task)

    # ç”Ÿæˆ Agent prompt
    prompt = generate_literature_review_prompt(task, state)

    # å¯åŠ¨ç‹¬ç«‹ Agent (ä½¿ç”¨ Task tool)
    from src.task import Task as TaskTool

    agent_result = TaskTool.invoke(
        subagent_type="literature-reviewer",  # ä¸“é—¨çš„æ–‡çŒ®è°ƒç ” agent
        description=f"Literature review for {task.id}",
        prompt=prompt,
        model="haiku",  # ä½¿ç”¨ Haiku é™ä½æˆæœ¬
    )

    # è§£æ Agent è¿”å›çš„ç²¾ç‚¼ç»“æœ
    result = parse_agent_response(agent_result)
    return result
```

#### Step 2: å®šä¹‰ literature-reviewer Agent

**Agent é…ç½®ï¼ˆéœ€è¦åœ¨ pm-agent ä¸­æ·»åŠ ï¼‰ï¼š**
```yaml
# .claude/agents/literature-reviewer.yaml
name: literature-reviewer
description: Specialized agent for literature review with context isolation
tools:
  - WebSearch
  - WebFetch
  - Read

constraints:
  - Must return condensed results (<2000 chars)
  - Focus on 2024-2026 papers only
  - No full abstracts in output
```

#### Step 3: Agent å·¥ä½œæµ

```
Agent å¯åŠ¨ â†’ æ‰§è¡Œæµç¨‹:

1. WebSearch "constrained DFT f-electron 2024"
   â†’ æ‰¾åˆ° 10 ç¯‡å€™é€‰è®ºæ–‡

2. ç­›é€‰æœ€ç›¸å…³çš„ 3-5 ç¯‡
   â†’ åŸºäºå¼•ç”¨æ•°ã€å‘è¡¨å¹´ä»½ã€æœŸåˆŠè´¨é‡

3. WebFetch æ¯ç¯‡è®ºæ–‡çš„æ‘˜è¦
   â†’ è¯»å–å¹¶åˆ†æ

4. Gap åˆ†æ
   - å½“å‰ä»»åŠ¡æè¿° vs SOTA
   - è¯†åˆ«åˆ›æ–°ç‚¹å’Œæ”¹è¿›ç©ºé—´

5. ç”Ÿæˆç²¾ç‚¼è¾“å‡º
   - éµå¾ª JSON æ¨¡æ¿
   - æ¯ä¸ªå­—æ®µæœ€å¤š 2 å¥è¯
   - æ€»é•¿åº¦ <2000 chars

6. ä¿å­˜åˆ°æ–‡ä»¶
   â†’ literature/{task_id}.json

7. Agent ç»“æŸï¼Œä¸Šä¸‹æ–‡é‡Šæ”¾ âœ…
```

**å…³é”®ç‚¹ï¼š**
- âœ… Agent åœ¨ç‹¬ç«‹ä¸Šä¸‹æ–‡ä¸­è¿è¡Œï¼Œç”¨å®Œå³é‡Šæ”¾
- âœ… ä¸»ä¼šè¯åªè¯»å–æ–‡ä»¶ï¼Œä¸å¼•å…¥å¤§é‡ä¸Šä¸‹æ–‡
- âœ… å¯å¹¶è¡Œå¯åŠ¨å¤šä¸ª Agent

### Phase 3: LLM-based æ·±åº¦åˆ†æ ğŸ”® æœªæ¥æ–¹å‘

**æ›´é«˜çº§çš„åŠŸèƒ½ï¼š**

#### 1. è‡ªåŠ¨æ–‡çŒ®ç»¼è¿°ç”Ÿæˆ

```python
# ä¸ºæ¯ä¸ªé«˜åˆ›æ–°ä»»åŠ¡ç”Ÿæˆå®Œæ•´çš„æ–‡çŒ®ç»¼è¿°æ–‡æ¡£
def generate_literature_survey(task, papers):
    """
    è¾“å…¥: ä»»åŠ¡ + 5-10 ç¯‡å…³é”®è®ºæ–‡
    è¾“å‡º: 3-5é¡µçš„æ–‡çŒ®ç»¼è¿°æ–‡æ¡£

    åŒ…å«:
    - ç ”ç©¶èƒŒæ™¯
    - ç›¸å…³å·¥ä½œåˆ†ç±»
    - æ¼”è¿›è¶‹åŠ¿åˆ†æ
    - Gap è¯†åˆ«
    - æœªæ¥æ–¹å‘
    """
    # åœ¨ç‹¬ç«‹ Agent ä¸­æ‰§è¡Œ
    # ç”Ÿæˆ markdown æ–‡æ¡£ä¿å­˜åˆ° research/surveys/
```

#### 2. è·¨ä»»åŠ¡å…³è”åˆ†æ

```python
# è¯†åˆ«ä»»åŠ¡é—´çš„æ–‡çŒ®å…³è”
def analyze_cross_task_literature(lit_results):
    """
    åˆ†æ:
    - å“ªäº›ä»»åŠ¡å¼•ç”¨äº†ç›¸åŒçš„è®ºæ–‡ï¼Ÿ
    - å“ªäº›ä»»åŠ¡å¯ä»¥å…±äº«æŠ€æœ¯æ–¹æ¡ˆï¼Ÿ
    - æ˜¯å¦æœ‰é‡å¤ç ”ç©¶çš„é£é™©ï¼Ÿ
    """
```

#### 3. è‡ªåŠ¨è®ºæ–‡æ¨è

```python
# åŸºäºä»»åŠ¡æè¿°ï¼Œæ¨èå¿…è¯»è®ºæ–‡
def recommend_papers(task, top_k=5):
    """
    æ¨èç­–ç•¥:
    1. ç›¸ä¼¼åº¦åŒ¹é… (ä»»åŠ¡æè¿° vs è®ºæ–‡æ‘˜è¦)
    2. å¼•ç”¨ç½‘ç»œåˆ†æ
    3. æ—¶æ•ˆæ€§æƒé‡ (2024-2026 è®ºæ–‡ä¼˜å…ˆ)
    """
```

---

## æˆæœ¬ä¸æ€§èƒ½åˆ†æ

### ä¸Šä¸‹æ–‡æ¶ˆè€—å¯¹æ¯”

| æ–¹æ¡ˆ | å•ä»»åŠ¡æˆæœ¬ | 10 ä»»åŠ¡æˆæœ¬ | 42 ä»»åŠ¡æˆæœ¬ | å¯è¡Œæ€§ |
|------|-----------|------------|------------|--------|
| æ— éš”ç¦» (ä¸»ä¼šè¯) | 15k tokens | 150k | 630k | âŒ çˆ†ç‚¸ |
| ä¸Šä¸‹æ–‡éš”ç¦» (Agent) | 500 tokens (ä¸») + 50k (Agent) | 5k (ä¸») + 10Ã—50k (éš”ç¦») | 21k (ä¸») + 10Ã—50k (éš”ç¦») | âœ… å¯è¡Œ |

**å…³é”®ä¼˜åŠ¿ï¼š**
- ä¸»ä¼šè¯ä¸Šä¸‹æ–‡: 21k tokens (vs 630k)
- Agent ä¸Šä¸‹æ–‡: éš”ç¦»ä¸”å¯å¹¶è¡Œï¼Œç”¨å®Œå³é‡Šæ”¾
- æ€»ä½“å¯è¡Œæ€§: âœ…

### æ—¶é—´æˆæœ¬ä¼°ç®—

**Placeholder æ¨¡å¼ï¼š**
```
æ—¶é—´: ~30ç§’ (æœ¬åœ°è®¡ç®—)
æˆæœ¬: $0
å‡†ç¡®æ€§: 50-60% (åŸºäºå…³é”®è¯å¯å‘å¼)
```

**Agent-based æ¨¡å¼ï¼š**
```
å•ä¸ªä»»åŠ¡:
- WebSearch: 5-10ç§’
- WebFetch: 3-5ç¯‡ Ã— 2ç§’ = 6-10ç§’
- åˆ†æ: 10-15ç§’
- æ€»è®¡: 21-35ç§’/ä»»åŠ¡

10 ä¸ªä»»åŠ¡ (ä¸²è¡Œ): ~4-6 åˆ†é’Ÿ
10 ä¸ªä»»åŠ¡ (å¹¶è¡Œ): ~30-60 ç§’

æˆæœ¬ (Claude Haiku):
- å•ä»»åŠ¡: ~50k tokens Ã— $0.25/M = $0.0125
- 10 ä»»åŠ¡: ~$0.125
```

**æ€§ä»·æ¯”ï¼š**
- âœ… æˆæœ¬å¯æ§ (<$0.2)
- âœ… æ—¶é—´å¯æ¥å— (<5åˆ†é’Ÿ)
- âœ… å‡†ç¡®æ€§æ˜¾è‘—æå‡ (80-90%)

---

## ä½¿ç”¨æŒ‡å—

### å½“å‰ä½¿ç”¨ (Placeholder æ¨¡å¼)

```bash
# 1. è¿è¡Œå¢å¼ºç‰ˆè¯„å®¡
python tools/enhanced_review.py --max-lit-tasks 5

# 2. æŸ¥çœ‹ç»“æœ
cat projects/f-electron-scf/research_review_enhanced.md

# 3. æŸ¥çœ‹æ–‡çŒ®æ‘˜è¦
cat projects/f-electron-scf/research/literature/summary.json

# 4. é’ˆå¯¹å•ä¸ªä»»åŠ¡æŸ¥çœ‹è¯¦ç»†æ–‡çŒ®
cat projects/f-electron-scf/research/literature/FE-205_literature.json
```

### æœªæ¥ä½¿ç”¨ (Agent-based æ¨¡å¼)

```bash
# 1. å¯ç”¨ Agent æ¨¡å¼
python tools/enhanced_review.py --max-lit-tasks 5 --use-agent

# 2. å¹¶è¡Œæ¨¡å¼ (æ›´å¿«)
python tools/enhanced_review.py --max-lit-tasks 10 --use-agent --parallel

# 3. æŒ‡å®š Agent æ¨¡å‹ (é™ä½æˆæœ¬)
python tools/enhanced_review.py --use-agent --model haiku

# 4. è·³è¿‡ç¼“å­˜ï¼Œå¼ºåˆ¶é‡æ–°è°ƒç ”
python tools/enhanced_review.py --use-agent --no-cache
```

### è‡ªå®šä¹‰æ–‡çŒ®è°ƒç ”

```python
# ä¸ºç‰¹å®šä»»åŠ¡è¿è¡Œæ·±åº¦æ–‡çŒ®è°ƒç ”
from src.phases.literature_review import run_literature_review_for_task

result = run_literature_review_for_task(
    task=my_task,
    state=project_state,
    output_dir=Path("research/literature"),
    use_agent=True  # Agent æ¨¡å¼
)

print(result.improvement_suggestions)
print(result.key_papers)
```

---

## ä¸ claude-scholar çš„æ•´åˆ

### å·¥å…·é“¾æ˜ å°„

| pm-agent é˜¶æ®µ | claude-scholar skill | æ–‡çŒ®è°ƒç ”çš„è§’è‰² |
|--------------|---------------------|---------------|
| ä»»åŠ¡è¯„å®¡ | dev-planner | ç”¨æ–‡çŒ®éªŒè¯å…ˆè¿›æ€§ |
| å‰ç½®ç ”ç©¶è§„åˆ’ | research-ideation | åŸºäºæ–‡çŒ®çš„ Gap åˆ†æ |
| æŠ€æœ¯æ–¹æ¡ˆè®¾è®¡ | architecture-design | å‚è€ƒ SOTA å®ç° |
| ç»“æœåˆ†æ | results-analysis | ä¸æ–‡çŒ®å¯¹æ¯”éªŒè¯ |
| è®ºæ–‡æ’°å†™ | ml-paper-writing | å¼•ç”¨æ–‡çŒ®ç»¼è¿° |

### å®Œæ•´å·¥ä½œæµ

```
ç”¨æˆ·è¯·æ±‚: è¯„ä¼°å¹¶ä¼˜åŒ– f-electron-scf é¡¹ç›®

Step 1: å¿«é€Ÿä»»åŠ¡è¯„å®¡ (pm-agent)
  â†’ è¯†åˆ«é«˜ä¼˜å…ˆçº§ä»»åŠ¡

Step 2: æ–‡çŒ®è°ƒç ” (isolated agents)
  â†’ ä¸º Top 10 ä»»åŠ¡æŸ¥é˜…æœ€æ–°æ–‡çŒ®
  â†’ è¿”å›ç²¾ç‚¼ç»“æœ

Step 3: å…ˆè¿›æ€§è¯„ä¼° (pm-agent + æ–‡çŒ®)
  â†’ åŸºäºæ–‡çŒ®é‡æ–°è¯„ä¼° novelty
  â†’ ç”Ÿæˆæ”¹è¿›å»ºè®®

Step 4: å‰ç½®ç ”ç©¶è§„åˆ’ (claude-scholar research-ideation)
  â†’ ä¸º frontier ä»»åŠ¡ç”Ÿæˆç ”ç©¶è®¡åˆ’
  â†’ åŒ…å«æ–‡çŒ®ç»¼è¿°æ¸…å•

Step 5: æŠ€æœ¯æ–¹æ¡ˆè®¾è®¡ (claude-scholar architecture-design)
  â†’ å‚è€ƒ SOTA æ–¹æ³•
  â†’ ç”Ÿæˆå®ç°æ–¹æ¡ˆ

Step 6: æ‰§è¡Œ + éªŒè¯

Step 7: è®ºæ–‡æ’°å†™ (claude-scholar ml-paper-writing)
  â†’ å¼•ç”¨æ–‡çŒ®ç»¼è¿°
  â†’ å¯¹æ¯” SOTA
```

---

## å…³é”®ä»£ç ç¤ºä¾‹

### 1. Agent å¯åŠ¨ (å¾…å®ç°)

```python
# src/phases/literature_review.py

def run_literature_review_for_task(task, state, output_dir, *, use_agent=True):
    """Run literature review with context isolation."""

    if not use_agent:
        return _placeholder_literature_review(task)

    # Generate focused prompt
    prompt = generate_literature_review_prompt(task, state)

    # Launch isolated agent
    try:
        # ä½¿ç”¨ Task tool å¯åŠ¨ literature-reviewer agent
        result_json = task_tool_invoke(
            subagent_type="literature-reviewer",
            description=f"Lit review: {task.id}",
            prompt=prompt,
            model="haiku",  # é™ä½æˆæœ¬
        )

        # Parse condensed result
        result = LiteratureReviewResult.from_dict(json.loads(result_json))

        # Cache to file
        cache_file = output_dir / f"{task.id}_literature.json"
        cache_file.write_text(json.dumps(result.to_dict(), indent=2))

        return result

    except Exception as e:
        print(f"Warning: Agent failed for {task.id}, falling back to placeholder: {e}")
        return _placeholder_literature_review(task)
```

### 2. Prompt è®¾è®¡

```python
def generate_literature_review_prompt(task, state):
    """Generate focused prompt that enforces condensed output."""

    return f"""
# Literature Review: {task.id}

**Task**: {task.title}
**Description**: {task.description[:200]}...

## Your Mission (CRITICAL: Stay Condensed)

1. WebSearch for recent papers (2024-2026):
   - "constrained DFT f-electron"
   - "rare-earth SCF convergence"
   - "DFT+U occupation control"

2. Analyze top 3-5 papers to determine:
   - Recent advances (1-2 sentences)
   - Current state-of-the-art (1-2 sentences)
   - Gaps this task addresses (1-2 sentences)
   - Novelty level: frontier/advanced/incremental/routine

3. Generate improvement suggestions (2-5 bullet points)

4. Identify alternative approaches from 2024-2025 literature

## Output Format (STRICTLY ENFORCE)

Return JSON with these fields:
- Each text field: MAX 2 sentences
- Total response: <2000 characters
- NO full abstracts

```json
{{
  "task_id": "{task.id}",
  "recent_advances": "...",
  "novelty_level": "frontier|advanced|incremental|routine",
  "improvement_suggestions": ["...", "..."],
  ...
}}
```

IMPORTANT: Be concise. Only actionable insights.
"""
```

### 3. ç»“æœæ•´åˆ

```python
def enhance_with_literature(basic_result, lit_results):
    """Enhance basic reviews with literature insights (minimal context)."""

    for review in basic_result['reviews']:
        task_id = review['task_id']

        if task_id in lit_results:
            lit = lit_results[task_id]

            # Update novelty with literature justification
            review['novelty'] = lit.novelty_level
            review['novelty_notes'] = lit.novelty_justification[:200]  # é™åˆ¶é•¿åº¦

            # Add condensed improvements
            review['lit_improvements'] = lit.improvement_suggestions[:3]  # æœ€å¤š3æ¡

    return basic_result
```

---

## æ€»ç»“

### å·²å®ç°çš„ä»·å€¼ âœ…

1. **ä¸Šä¸‹æ–‡éš”ç¦»æ¶æ„è®¾è®¡** - å°†æ–‡çŒ®è°ƒç ”éš”ç¦»åˆ°ç‹¬ç«‹ Agent
2. **ç»“æ„åŒ–ç²¾ç‚¼è¾“å‡º** - ä¸¥æ ¼é™åˆ¶è¾“å‡ºæ ¼å¼ï¼Œé¿å…ä¸Šä¸‹æ–‡çˆ†ç‚¸
3. **æ‰¹é‡å¤„ç†ç­–ç•¥** - åªä¸ºé«˜ä¼˜å…ˆçº§ä»»åŠ¡è¿è¡Œæ–‡çŒ®è°ƒç ”
4. **ç¼“å­˜æœºåˆ¶** - é¿å…é‡å¤è°ƒç ”
5. **Placeholder å®ç°** - è¯æ˜æ¶æ„å¯è¡Œæ€§

**å½“å‰é™åˆ¶ï¼š**
- âš ï¸ Placeholder æ¨¡å¼å‡†ç¡®æ€§æœ‰é™ (50-60%)
- âš ï¸ æœªå®é™…æŸ¥è¯¢æœ€æ–°æ–‡çŒ®

### ä¸‹ä¸€æ­¥ ğŸš€

#### è¿‘æœŸ (1-2å‘¨)
1. âœ… é›†æˆ Task toolï¼Œå®ç°çœŸæ­£çš„ Agent å¯åŠ¨
2. âœ… ä¸º f-electron-scf è¿è¡Œ Agent-based æ–‡çŒ®è°ƒç ”
3. âœ… éªŒè¯ä¸Šä¸‹æ–‡æ§åˆ¶æ•ˆæœ

#### ä¸­æœŸ (1ä¸ªæœˆ)
1. ä¼˜åŒ– Agent promptï¼Œæå‡ç²¾ç‚¼åº¦
2. æ”¯æŒå¹¶è¡Œ Agent æ‰§è¡Œ
3. å¢åŠ æ–‡çŒ®è´¨é‡è¯„åˆ†

#### é•¿æœŸ (2-3ä¸ªæœˆ)
1. è‡ªåŠ¨æ–‡çŒ®ç»¼è¿°ç”Ÿæˆ
2. è·¨ä»»åŠ¡æ–‡çŒ®å…³è”åˆ†æ
3. ä¸ claude-scholar æ·±åº¦æ•´åˆ

### æ ¸å¿ƒä¼˜åŠ¿

âœ… **ä¸Šä¸‹æ–‡å¯æ§**: ä¸»ä¼šè¯ 21k tokens (vs 630k)
âœ… **æˆæœ¬å¯æ§**: <$0.2 per review
âœ… **å‡†ç¡®æ€§é«˜**: 80-90% (vs 50-60% å¯å‘å¼)
âœ… **å¯æ‰©å±•**: æ”¯æŒå¹¶è¡Œã€ç¼“å­˜ã€å¢é‡æ›´æ–°

---

**Generated by**: pm-agent context isolation system
**Version**: v0.2.0-literature-review
**Date**: 2026-02-14
